# PubMed
В проекте мы производим FT GPT-2 с помощью LoRa  на медецинских данных ,и проверяем точность ответов на QA датасете с ответами (yes/no)

## Данные

В проекте использовались следующие датасеты
PubMedQA - https://huggingface.co/datasets/qiaojin/PubMedQA
PubMed - https://huggingface.co/datasets/ncbi/pubmed

## Ход работы
В файле nootebooks/TokeniseData.ipynb происходиоа токенизация датасета PubMed
Используя LoRa на данных из PubMed обучалась модель 
Цикл обучения в nootebooks/StudyModel.ipynb 
Далее произовдились замеры эфективности модели на PubMedQA
Код оценки в nootebooks/LaunchExperiments.ipynb

## Итоговые результаты
| GPT-2 | Precision | Recall |
| ----- | --------- | ------ |
| yes   | 0.576     | 0.496  |
| no    | 0.397     | 0.447  |

| LoRA GPT-2 | Precision | Recall |
| ---------- | --------- | ------ |
| yes        | 0. 6      | 0.0271 |
| no         | 0.46      | 0.1213 |


По этим таблицам видно ,что у доученной модели возрос precision ,но уменьшился Recall.Модель более точно , но боиться ошибаться .И самое заметное суммарный Reacall модели сильно меньше 1 ,это значит что доученная модель сильно потеряла способность к генерации текста в отличии от оригинала.
Возможно при следующих эксперементах следует уменьшить влияние LoRa на модель .И лучше подобрать гиперпараметры


